{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Define Neo4j connections\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "\n",
    "host = 'bolt://localhost:7687'\n",
    "user = 'neo4j'\n",
    "password = 'wowhi223'\n",
    "driver = GraphDatabase.driver(host,auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema_query = \"\"\"\n",
    "\n",
    "CALL apoc.schema.assert( \n",
    "    // define indexes \n",
    "    null, \n",
    "    // define unique constraints \n",
    "    {Ingredient:['name'], Dish:['id'], DishType:['name']})\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "graph_import_query = \"\"\"\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM \"file:///newfood.csv\" as row \n",
    "CREATE (d:Dish{id:row.id}) \n",
    "SET d += apoc.map.clean(row, ['id','dishTypes','ingredients'],[]) \n",
    "FOREACH (i in split(row.ingredients,',') | MERGE (in:Ingredient{name:toLower(replace(i,'-',' '))}) \n",
    "                                           MERGE (in)<-[:HAS_INGREDIENT]-(d)) \n",
    "FOREACH (dt in split(row.dishTypes,',')  | MERGE (dts:DishType{name:dt}) \n",
    "                                           MERGE (dts)<-[:DISH_TYPE]-(d))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(graph_schema_query)\n",
    "    session.run(graph_import_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(\"\"\"CALL gds.graph.create('all', \n",
    "    '*', \n",
    "    {ALL_UNDIRECTED: {type:'*', orientation:'UNDIRECTED'}})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KT', 0.9990994930267334),\n",
       " ('서울도시가스', 0.9990705251693726),\n",
       " ('제공', 0.9990437626838684),\n",
       " ('온누리약국', 0.9988678097724915),\n",
       " ('국토교통부', 0.9988675713539124),\n",
       " ('졸업증명서', 0.9988021850585938),\n",
       " ('강민석', 0.9987440705299377),\n",
       " ('가공', 0.9987295866012573),\n",
       " ('인터파크', 0.9986906051635742),\n",
       " ('여권', 0.9986632466316223)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define random walk query\n",
    "random_walks_query = \"\"\"\n",
    "\n",
    "MATCH (node)\n",
    "CALL gds.alpha.randomWalk.stream('all', {\n",
    "  start: id(node),\n",
    "  steps: 15,\n",
    "  walks: 5\n",
    "})\n",
    "YIELD nodeIds\n",
    "// Return the names or the titles\n",
    "RETURN [id in nodeIds | \n",
    "    coalesce(gds.util.asNode(id).name, \n",
    "             gds.util.asNode(id).title)] as walks\n",
    "\n",
    "\"\"\"\n",
    "# Fetch data from Neo4j\n",
    "with driver.session() as session:\n",
    "    walks = session.run(random_walks_query)\n",
    "# Train the word2vec model\n",
    "clean_walks = [row['walks'] for row in walks]\n",
    "model = Word2Vec(clean_walks, sg=1, window=5, size=100)\n",
    "# Inspect results\n",
    "model.wv.most_similar('우리은행')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99799913"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('우리은행','이상우')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('서울도시가스', 0.9993897080421448),\n",
       " ('온누리약국', 0.9993473887443542),\n",
       " ('강민석', 0.999250054359436),\n",
       " ('졸업증명서', 0.9991940855979919),\n",
       " ('네이버', 0.9991650581359863)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['우리은행','이상우','차번호'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('주민번호', 0.9973477721214294),\n",
       " ('김수정', 0.9972724914550781),\n",
       " ('주소', 0.9968128204345703),\n",
       " ('네이버', 0.9966692924499512),\n",
       " ('온누리약국', 0.9966692328453064),\n",
       " ('강민석', 0.9966251254081726),\n",
       " ('서울도시가스', 0.9963914155960083),\n",
       " ('졸업증명서', 0.9963417053222656),\n",
       " ('가공', 0.9959931373596191),\n",
       " ('제공', 0.9955015182495117)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['이상우','차번호'], negative=['우리은행'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
